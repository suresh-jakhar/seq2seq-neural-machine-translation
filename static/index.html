<!-- Web interface for translation -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Seq2Seq Neural Machine Translation</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="header-content">
            <div class="logo">Seq2Seq NMT</div>
            <nav>
                <a href="#hero" class="active">
                    <svg class="icon" viewBox="0 0 24 24">
                        <path d="M5 8l6 6M4 14l6-6-6-6M15 8h4M17 8v8"/>
                    </svg>
                    <span>Translator</span>
                </a>
                <a href="#api">
                    <svg class="icon" viewBox="0 0 24 24">
                        <rect x="3" y="3" width="18" height="18" rx="2"/>
                        <path d="M9 3v18M3 9h18M3 15h18"/>
                    </svg>
                    <span class="full-text">API Documentation</span>
                    <span class="short-text">API Docs</span>
                </a>
                <a href="#about">
                    <svg class="icon" viewBox="0 0 24 24">
                        <circle cx="12" cy="12" r="10"/>
                        <path d="M12 16v-4M12 8h.01"/>
                    </svg>
                    <span>About Project</span>
                </a>
            </nav>
        </div>
    </header>

    <main>
        <!-- Hero -->
        <section id="hero" class="hero">
            <div class="container">
                <h1>Neural Machine Translation</h1>
                <p>English to French translation powered by a custom-trained Transformer model</p>
            </div>
        </section>

        <!-- Translator -->
        <section id="translator" class="container">
            <div class="translator">
                <div class="translator-card">
                    <div class="translator-grid">
                        <div class="input-group">
                            <div class="input-label">
                                <svg class="icon" viewBox="0 0 24 24">
                                    <rect x="3" y="3" width="18" height="18" rx="2"/>
                                    <path d="M7 7h10M7 12h10M7 17h7"/>
                                </svg>
                                English
                            </div>
                            <textarea id="inputText" placeholder="Enter text to translate..."></textarea>
                        </div>
                        <div class="arrow-separator">
                            <svg class="arrow-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                <path d="M5 12h14M12 5l7 7-7 7"/>
                            </svg>
                        </div>
                        <div class="input-group">
                            <div class="input-label">
                                <svg class="icon" viewBox="0 0 24 24">
                                    <path d="M5 8l6 6M4 14l6-6M15 8l4 0M17 8l0 8"/>
                                    <circle cx="17" cy="16" r="0.5" fill="currentColor"/>
                                </svg>
                                French
                            </div>
                            <textarea id="outputText" placeholder="Translation will appear here..." readonly></textarea>
                            <div class="loading-dots" id="loadingDots">
                                <span></span>
                                <span></span>
                                <span></span>
                            </div>
                            <div class="error-message" id="errorMessage"></div>
                        </div>
                    </div>
                    <div class="controls">
                        <button id="clearBtn">Clear</button>
                        <button id="translateBtn" class="primary">Translate</button>
                    </div>
                    <div id="statusMessage" class="status"></div>
                </div>
            </div>
        </section>

        <!-- API Documentation -->
        <section id="api" class="section">
            <div class="container">
                <h2>API Reference</h2>
                <p class="api-intro">The Seq2Seq NMT API provides programmatic access to our neural machine translation system. Use this API to integrate English to French translation into your applications.</p>

                <div class="content-box content-box-info">
                    <p class="base-url"><strong>Base URL:</strong> <code class="base-url-code">https://sureshjakhar-seq2seq-neural-machine-translation.hf.space</code></p>
                </div>

                <h3>Authentication</h3>
                <div class="content-box">
                    <p>No authentication required. This API is publicly accessible.</p>
                </div>

                <h3>Endpoints</h3>
                
                <div class="content-box">
                                        <p class="endpoint-title">POST /translate</p>
                                        <p class="endpoint-desc">Translate text from English to French using our custom-trained Transformer model.</p>
                    
                                        <p class="section-label">Request Body</p>
                    <pre><code>{
  "text": "string"  // Required: English text to translate (max 48 tokens)
}</code></pre>

                                        <p class="section-label section-label-spaced">Response</p>
                    <pre><code>{
  "original_text": "string",
  "success": true,
  "translated_text": "string"
}</code></pre>

                                        <p class="section-label section-label-spaced">Example Request</p>
                    <pre><code>curl -X POST https://sureshjakhar-seq2seq-neural-machine-translation.hf.space/translate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello, how are you today?"
  }'</code></pre>

                                        <p class="section-label section-label-spaced">Example Response</p>
                    <pre><code>{
  "original_text": "Hello, how are you today?",
  "success": true,
  "translated_text": "bonjour, comment allez-vous aujourd'hui?"
}</code></pre>
                </div>

                <div class="content-box">
                                        <p class="endpoint-title">GET /health</p>
                                        <p class="endpoint-desc">Check the health status of the translation service.</p>
                    
                                        <p class="section-label">Response</p>
                    <pre><code>{
  "device": "cpu",
  "model_loaded": true,
  "status": "healthy",
  "tokenizer_loaded": true
}</code></pre>
                </div>

                <div class="content-box">
                                        <p class="endpoint-title">GET /api</p>
                                        <p class="endpoint-desc">Retrieve API metadata and available endpoints.</p>
                    
                                        <p class="section-label">Response</p>
                    <pre><code>{
  "endpoints": {
    "/health": "GET - Health check",
    "/translate": "POST - Translate text to French"
  },
  "message": "Seq2Seq Neural Machine Translation",
  "version": "1.0"
}</code></pre>
                </div>

                <h3>Error Handling</h3>
                <div class="content-box">
                    <p>The API uses standard HTTP response codes. Errors return JSON with an <code>error</code> field and detailed <code>message</code>.</p>
                    
                                        <p class="section-label section-label-spaced-sm">Error Response Format</p>
                    <pre><code>{
  "error": "string",
  "message": "Detailed error description"
}</code></pre>

                                        <p class="section-label section-label-spaced-md">Common Error Codes</p>
                    <p><strong>400 Bad Request</strong> - No data provided or missing "text" field</p>
                    <p><strong>500 Internal Server Error</strong> - Translation failed during processing</p>
                    <p><strong>503 Service Unavailable</strong> - Translation model not loaded</p>
                </div>

                <h3>Rate Limits</h3>
                <div class="content-box">
                    <p>Currently, there are no rate limits enforced. However, please use the API responsibly. For production use cases requiring higher throughput, consider deploying your own instance.</p>
                </div>

                <h3>SDK Examples</h3>
                <div class="content-box">
                    <p class="section-label">Python</p>
                    <pre><code>import requests

class Seq2SeqTranslator:
    def __init__(self):
        self.base_url = "https://sureshjakhar-seq2seq-neural-machine-translation.hf.space"
    
    def translate(self, text):
        response = requests.post(
            f"{self.base_url}/translate",
            json={"text": text},
            headers={"Content-Type": "application/json"}
        )
        return response.json()

# Usage
translator = Seq2SeqTranslator()
result = translator.translate("Hello world")
print(result["translated_text"])</code></pre>

                    <p class="section-label section-label-spaced">JavaScript/Node.js</p>
                    <pre><code>const translate = async (text) => {
  const response = await fetch(
    'https://sureshjakhar-seq2seq-neural-machine-translation.hf.space/translate',
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text })
    }
  );
  return await response.json();
};

// Usage
translate("Hello world")
  .then(result => console.log(result.translated_text))
  .catch(error => console.error(error));</code></pre>
                </div>
            </div>
        </section>

        <!-- About -->
        <section id="about" class="section">
            <div class="container">
                <h2>About This Project</h2>
                <p class="about-subtitle">By Suresh Jakhar</p>

                <h3>Training of a Translation Model</h3>
                <div class="content-box">
                    <p>An attempt to understand what it actually takes to train a translation model from scratch on a mid range laptop with 8GB RAM, no dedicated GPU, running entirely on CPU. The dataset was not enormous by machine translation standards roughly two hundred thousand parallel English French sentences but it was large enough to make the task real, and small enough that every design decision mattered.</p>

                    <p>The first challenge was representation. Word level models were out of the question: they explode in vocabulary size and produce many unknown tokens for rare words. Instead, I adopted a SentencePiece tokenizer with the unigram language model and trained it directly on the combined English French corpus. This joint subword model carved both languages into a shared space of 8,000 tokens, compact enough for the small dataset while preserving linguistic structure.</p>

                    <p>With the tokenizer in place, the model itself took shape not a giant pretrained system, but a compact Transformer the student could actually train. Four encoder layers, four decoder layers, a hidden dimension of 384, six attention heads, and feed forward networks scaled to 1,024 units. It resembled the original Transformer architecture in structure but was pared down deliberately to avoid memory issues. Positional encodings remained sinusoidal, and the embedding matrix was tied to the output projection a small but important act of parameter discipline.</p>

                    <p>The first attempts crashed with out of memory errors; even when they ran, gradients exploded or drifted unpredictably. The solution was not to shrink the architecture, but to re think how updates were computed. Gradient accumulation became the central mechanism processing several micro batches and combining their gradients before each optimization step. This approximated larger batch training by summing gradients, though not perfectly replicating all batch level dynamics.</p>

                    <p>Optimization followed a similarly careful path. AdamW provided weight decoupled regularization, while the Noam warmup schedule stabilized the early phase of training where Transformers are most fragile. Automatic mixed precision helped the model fit in memory, though it required gradient scaling to handle numerical stability. Label smoothing softened the learning signal and prevented the decoder from becoming overconfident. Attention masks prevented the model from attending to future tokens (causal masking) or padded positions (padding masks), maintaining the mathematical integrity of the sequence-to-sequence formulation.</p>

                    <p>The model began to translate, gradually improving with each epoch. What emerged was not a production grade system but a functioning demonstration of how a translation model can be built from scratch.</p>

                    <p>I produced several artifacts: a trained SentencePiece tokenizer, a compact Transformer checkpoint, and a translation engine capable of converting English sentences into French. The real achievement was understanding how tokenization shapes model behavior, how architecture must bend to hardware limits, how learning rate schedules prevent collapse, and how stability techniques such as gradient accumulation turn an otherwise impossible task into a successful experiment.</p>

                    <p>A practical lesson in modern NLP engineering: even with limited resources, a well designed model, a disciplined training strategy, and the willingness to iterate can produce a translation system that works.</p>
                </div>

                <h3>Deployment and MLOps</h3>
                <div class="content-box">
                    <p>Training a model is one thing. Making it accessible, testable, and deployable is another entirely. The challenge: how to take a model file sitting on a local machine and turn it into something that runs reliably, can be tested automatically, and deploys without manual intervention. The first instinct was simple: write a Flask API, wrap the model in an endpoint, and call it done. A POST /translate route accepted English text, ran it through the Transformer, and returned French. Locally it worked, but sharing it became complicated.</p>

                    <p>GitHub was the starting point. But the model file was 72 megabytes, and the tokenizer another few megabytes. GitHub warns at 50MB and blocks files over 100MB. The solution was Git LFS for versioning large files. Configuring it meant creating a .gitattributes file, marking *.pt and *.model as LFS tracked. It was tedious but necessary.</p>

                    <p>Then came testing with pytest: health endpoint, valid inputs, empty strings, missing fields, JSON edge cases. Each test was a contract: if this input goes in, this behavior must come out. Running them before every commit required automation. GitHub Actions provided continuous integration: every push triggers an automated workflow that installs dependencies, executes tests, and reports results. Once tests passed, deployment to Hugging Face Spaces was next. I configured the Space to Docker mode manually, which reads the Dockerfile, builds a container, and serves the app. Files over 10 megabytes must be tracked by Git LFS. The 176 megabyte training dataset violated this rule. The fix required rewriting git history with git filter repo and using a .hfignore file. It was messy, but it worked.</p>

                    <p>The result was an automated pipeline. Code pushed to GitHub triggers automated tests. If tests pass, a Docker image builds and pushes to Docker Hub. Simultaneously, Hugging Face Spaces builds and deploys the live demo.</p>
                </div>

                <h3>What I Learned</h3>
                <div class="content-box">
                    <p>This project taught me the real gap between a model that runs locally and a system that works reliably. Limited RAM on CPU only hardware forced deliberate design: choosing fewer layers, using gradient accumulation, and treating tokenization, learning rate schedules, and precision as architectural decisions, not routine settings. Those constraints shaped how I approached optimization and made efficiency a requirement, not an afterthought. But once the model trained, the real lessons began APIs, error handling, logging, and clear contracts turned it from an experiment into something others could actually use. Git taught me that large files require LFS, that history sometimes needs rewriting with tools like git filter repo, and that version control is part of engineering, not bookkeeping.</p>

                    <p>Automation, containerization, and deployment completed the education. CI/CD pipelines exposed hidden assumptions and enforced consistency. Docker clarified what reproducibility means and why production must be treated as a separate environment. Deploying to Hugging Face and Docker Hub taught me how authentication, file limits, and strict configurations work. Debugging logs, fixing mismatches, and refining workflows showed that system reliability depends on discipline, iteration, and attention to detail. Building ML systems is far more than training models it's about the infrastructure, automation, and engineering that make the model stable, accessible, and maintainable.</p>
                </div>

                <h3>Technical Specifications</h3>
                <div class="content-box">
                    <p><strong>Architecture:</strong> Transformer (4 encoder layers, 4 decoder layers, 384 hidden dimensions, 6 attention heads)</p>
                    <p><strong>Training:</strong> 200K parallel sentences, SentencePiece unigram tokenization (8K vocabulary), AdamW optimizer with Noam warmup, gradient accumulation, mixed precision with gradient scaling</p>
                    <p><strong>Deployment:</strong> Flask API, Docker containerization, GitHub Actions CI/CD, Hugging Face Spaces hosting</p>
                    <p><strong>Testing:</strong> Automated unit tests with pytest, 92% code coverage, linting with flake8</p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>Built by Suresh Jakhar Â· <a href="https://github.com/suresh-jakhar/seq2seq-neural-machine-translation">View on GitHub</a></p>
        </div>
    </footer>

    <script>
        // Smooth scroll for navigation
        document.querySelectorAll('nav a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth', block: 'start' });
                    // Update active state
                    document.querySelectorAll('nav a').forEach(a => a.classList.remove('active'));
                    this.classList.add('active');
                }
            });
        });

        // Live translation functionality
        const inputText = document.getElementById('inputText');
        const outputText = document.getElementById('outputText');
        const loadingDots = document.getElementById('loadingDots');
        const errorMessage = document.getElementById('errorMessage');
        let translationTimeout;
        let currentRequest;

        async function liveTranslate() {
            const text = inputText.value.trim();
            
            // Clear previous timeout
            clearTimeout(translationTimeout);
            
            // If no text, clear output
            if (!text) {
                outputText.value = '';
                errorMessage.classList.remove('show');
                return;
            }

            // Show loading
            loadingDots.style.display = 'inline-flex';
            outputText.value = '';
            errorMessage.classList.remove('show');

            // Cancel previous request if exists
            if (currentRequest) {
                currentRequest.abort();
            }

            try {
                const controller = new AbortController();
                currentRequest = controller;

                const response = await fetch('/translate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text }),
                    signal: controller.signal
                });

                const data = await response.json();

                if (response.ok && data.success) {
                    outputText.value = data.translated_text;
                } else {
                    errorMessage.textContent = data.message || 'Translation failed';
                    errorMessage.classList.add('show');
                }
            } catch (error) {
                if (error.name !== 'AbortError') {
                    errorMessage.textContent = 'Unable to connect to translation service';
                    errorMessage.classList.add('show');
                }
            } finally {
                loadingDots.style.display = 'none';
                currentRequest = null;
            }
        }

        // Debounce live translation (wait 800ms after user stops typing)
        inputText.addEventListener('input', () => {
            clearTimeout(translationTimeout);
            translationTimeout = setTimeout(liveTranslate, 800);
        });

        // Also translate on Enter key (without debounce)
        inputText.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && e.ctrlKey) {
                clearTimeout(translationTimeout);
                liveTranslate();
            }
        });

        // Update active navigation on scroll
        const sections = document.querySelectorAll('section[id]');
        const navLinks = document.querySelectorAll('nav a[href^="#"]');

        function updateActiveNav() {
            const scrollPosition = window.scrollY + 100; // Offset for fixed header

            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.offsetHeight;
                const sectionId = section.getAttribute('id');

                if (scrollPosition >= sectionTop && scrollPosition < sectionTop + sectionHeight) {
                    navLinks.forEach(link => {
                        link.classList.remove('active');
                        if (link.getAttribute('href') === `#${sectionId}`) {
                            link.classList.add('active');
                        }
                    });
                }
            });
        }

        window.addEventListener('scroll', updateActiveNav);
        window.addEventListener('load', updateActiveNav);
    </script>
</body>
</html>
